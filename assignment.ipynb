{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26741408-099e-4d28-97dc-e7df874f169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer : 1\n",
    "    \n",
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use Bayes' theorem. Let's denote:\n",
    "\n",
    "- A: Event that an employee is a smoker.\n",
    "- B: Event that an employee uses the company's health insurance plan.\n",
    "\n",
    "We want to find \\( P(A|B) \\), the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
    "\n",
    "Bayes' theorem states:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "We are given:\n",
    "\n",
    "- \\( P(B) \\), the probability that an employee uses the company's health insurance plan, which is 70% or 0.70.\n",
    "- \\( P(A|B) \\), the probability that an employee is a smoker given that he/she uses the health insurance plan, which is 40% or 0.40.\n",
    "- \\( P(A) \\), the overall probability that an employee is a smoker. This is not directly given but can be calculated from the information provided.\n",
    "\n",
    "To find \\( P(A) \\), we can use the law of total probability, which states:\n",
    "\n",
    "\\[ P(A) = P(A \\cap B) + P(A \\cap B') \\]\n",
    "\n",
    "Where \\( B' \\) represents the event that an employee does not use the company's health insurance plan.\n",
    "\n",
    "Given that 70% of the employees use the health insurance plan, \\( P(B) = 0.70 \\). Therefore, \\( P(B') = 1 - P(B) = 0.30 \\).\n",
    "\n",
    "We are also given \\( P(B|A) \\), the probability that an employee uses the health insurance plan given that he/she is a smoker, which is 40% or 0.40.\n",
    "\n",
    "Now we can calculate \\( P(A) \\):\n",
    "\n",
    "\\[ P(A) = P(A \\cap B) + P(A \\cap B') \\]\n",
    "\\[ P(A) = P(B|A) \\times P(A) + P(B'|A') \\times P(A') \\]\n",
    "\n",
    "We don't have direct information about \\( P(A') \\), the probability that an employee is not a smoker, but we can calculate it using \\( P(A') = 1 - P(A) \\).\n",
    "\n",
    "Now, let's compute \\( P(A) \\) and then use Bayes' theorem to find \\( P(A|B) \\).\n",
    "\n",
    "To find \\( P(A) \\), we can use the law of total probability:\n",
    "\n",
    "\\[ P(A) = P(A \\cap B) + P(A \\cap B') \\]\n",
    "\n",
    "We are given:\n",
    "\n",
    "- \\( P(B) \\), the probability that an employee uses the company's health insurance plan, which is 70% or 0.70.\n",
    "- \\( P(A|B) \\), the probability that an employee is a smoker given that he/she uses the health insurance plan, which is 40% or 0.40.\n",
    "- \\( P(B'|A') \\), the probability that an employee does not use the health insurance plan given that he/she is not a smoker. Since this information is not directly given, we need to calculate it.\n",
    "\n",
    "Let's denote:\n",
    "- \\( P(A') \\), the probability that an employee is not a smoker.\n",
    "- \\( P(B'|A') \\), the probability that an employee does not use the health insurance plan given that he/she is not a smoker.\n",
    "\n",
    "We have:\n",
    "- \\( P(A') = 1 - P(A) \\), which we can calculate.\n",
    "- \\( P(B'|A') = 1 \\), since if an employee is not a smoker, they must use the health insurance plan (as per the information provided).\n",
    "\n",
    "Let's calculate \\( P(A) \\) and then use Bayes' theorem to find \\( P(A|B) \\):\n",
    "\n",
    "\\[ P(A) = P(A \\cap B) + P(A \\cap B') \\]\n",
    "\\[ P(A) = P(B|A) \\times P(A) + P(B'|A') \\times P(A') \\]\n",
    "\n",
    "Given:\n",
    "- \\( P(B|A) = 0.40 \\) (probability that an employee uses the health insurance plan given that he/she is a smoker)\n",
    "- \\( P(B) = 0.70 \\) (probability that an employee uses the health insurance plan)\n",
    "- \\( P(A|B) = 0.40 \\) (probability that an employee is a smoker given that he/she uses the health insurance plan)\n",
    "\n",
    "Let's proceed with the calculations:\n",
    "\n",
    "\\[ P(A) = (0.40 \\times P(A)) + (1 \\times (1 - P(A))) \\]\n",
    "\n",
    "Now, solve for \\( P(A) \\):\n",
    "\n",
    "\\[ P(A) = 0.40 \\times P(A) + 1 - P(A) \\]\n",
    "\\[ P(A) = 0.40P(A) + 1 - P(A) \\]\n",
    "\\[ P(A) = 0.40P(A) + 1 - P(A) \\]\n",
    "\\[ P(A) = 0.40P(A) + 1 - P(A) \\]\n",
    "\\[ P(A) = 0.40P(A) + 1 - P(A) \\]\n",
    "\\[ P(A) = 0.40P(A) + 1 - P(A) \\]\n",
    "\n",
    "Therefore, \\( P(A) = \\frac{1}{1.4} \\).\n",
    "\n",
    "Now, we can use Bayes' theorem to find \\( P(A|B) \\):\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "\n",
    "Substitute the values we have:\n",
    "\n",
    "\\[ P(A|B) = \\frac{0.40 \\times \\frac{1}{1.4}}{0.70} \\]\n",
    "\n",
    "Now, calculate \\( P(A|B) \\):\n",
    "\n",
    "\\[ P(A|B) = \\frac{0.40 \\times \\frac{1}{1.4}}{0.70} \\]\n",
    "\\[ P(A|B) = \\frac{0.40 \\times \\frac{1}{1.4}}{0.70} \\]\n",
    "\\[ P(A|B) = \\frac{0.40 \\times \\frac{1}{1.4}}{0.70} \\]\n",
    "\\[ P(A|B) â‰ˆ 0.381 \\]\n",
    "\n",
    "So, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately 0.381 or 38.1%.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd12d6-4382-42b5-be02-8424716af47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer : 2\n",
    "    \n",
    "The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type of features they are designed to handle and the underlying probability distributions they assume.\n",
    "\n",
    "1. **Bernoulli Naive Bayes**:\n",
    "   - Bernoulli Naive Bayes is typically used when features are binary-valued (i.e., they represent presence or absence of a particular term).\n",
    "   - It assumes that features are generated from a Bernoulli distribution, where each feature is independent and follows a Bernoulli distribution with a parameter \\( \\theta \\), representing the probability of occurrence of the feature.\n",
    "   - It's commonly used in text classification tasks, where features represent the presence or absence of certain words in a document.\n",
    "   - For example, in sentiment analysis, a Bernoulli Naive Bayes classifier might consider whether certain words (e.g., \"good\", \"bad\") are present in a document.\n",
    "\n",
    "2. **Multinomial Naive Bayes**:\n",
    "   - Multinomial Naive Bayes is suitable for features that represent counts or frequencies (i.e., they are integer-valued and represent the number of occurrences of each term).\n",
    "   - It assumes that features are generated from a multinomial distribution, where each feature is independent and follows a multinomial distribution with parameters \\( \\theta_1, \\theta_2, ..., \\theta_n \\), representing the probabilities of each possible outcome.\n",
    "   - It's commonly used in text classification tasks, particularly when features represent word counts or frequencies in a document.\n",
    "   - For example, in document classification, a Multinomial Naive Bayes classifier might consider the frequency of each word in a document.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes is appropriate for binary features, while Multinomial Naive Bayes is suitable for features that represent counts or frequencies. Both classifiers make the assumption of feature independence given the class label (hence the \"naive\" assumption), but they differ in the underlying probability distributions assumed for the features.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e7dde-0983-4db1-afb4-c45e29c60e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer : 3\n",
    "    \n",
    "Naive Bayes can handle missing data. Attributes are handled separately by the algorithm, at both model construction\n",
    "time and prediction time. As such, if a data instance has a missing value for an attribute, it can be ignored while preparing the model,\n",
    "and ignored when a probability is calculated for a class value.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07e193-5be3-45bc-b24f-8834e1360035",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer : 4\n",
    "    \n",
    "The Naive Bayes algorithm can be used for multi-class classification problems with more than two classes.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84abd2-e27d-4393-890d-5ed4e1752594",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Answer : 5\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "# Load the Spambase dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "names = [\n",
    "    \"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\",\n",
    "    \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\",\n",
    "    \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\",\n",
    "    \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\",\n",
    "    \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
    "    \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\",\n",
    "    \"word_freq_hp\", \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\",\n",
    "    \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\", \"word_freq_857\",\n",
    "    \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\",\n",
    "    \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "    \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\",\n",
    "    \"word_freq_re\", \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\",\n",
    "    \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\",\n",
    "    \"char_freq_#\", \"capital_run_length_average\", \"capital_run_length_longest\",\n",
    "    \"capital_run_length_total\", \"is_spam\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(url, header=None, names=names)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('is_spam', axis=1)\n",
    "y = data['is_spam']\n",
    "\n",
    "# Implement Bernoulli Naive Bayes\n",
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_scores = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Implement Multinomial Naive Bayes\n",
    "multinomial_nb = MultinomialNB()\n",
    "multinomial_scores = cross_val_score(multinomial_nb, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Implement Gaussian Naive Bayes\n",
    "gaussian_nb = GaussianNB()\n",
    "gaussian_scores = cross_val_score(gaussian_nb, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Report performance metrics\n",
    "print(\"Performance Metrics:\")\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", np.mean(bernoulli_scores))\n",
    "print(\"Precision:\", np.mean(cross_val_score(bernoulli_nb, X, y, cv=10, scoring='precision')))\n",
    "print(\"Recall:\", np.mean(cross_val_score(bernoulli_nb, X, y, cv=10, scoring='recall')))\n",
    "print(\"F1 Score:\", np.mean(cross_val_score(bernoulli_nb, X, y, cv=10, scoring='f1')))\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\", np.mean(multinomial_scores))\n",
    "print(\"Precision:\", np.mean(cross_val_score(multinomial_nb, X, y, cv=10, scoring='precision')))\n",
    "print(\"Recall:\", np.mean(cross_val_score(multinomial_nb, X, y, cv=10, scoring='recall')))\n",
    "print(\"F1 Score:\", np.mean(cross_val_score(multinomial_nb, X, y, cv=10, scoring='f1')))\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes:\")\n",
    "print(\"Accuracy:\", np.mean(gaussian_scores))\n",
    "print(\"Precision:\", np.mean(cross_val_score(gaussian_nb, X, y, cv=10, scoring='precision')))\n",
    "print(\"Recall:\", np.mean(cross_val_score(gaussian_nb, X, y, cv=10, scoring='recall')))\n",
    "print(\"F1 Score:\", np.mean(cross_val_score(gaussian_nb, X, y, cv=10, scoring='f1')))\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
